{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyphrase Extraction using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MZ5l07pXuVj",
        "colab_type": "text"
      },
      "source": [
        "# Keyword-Extraction using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2KAPqvEXw_o",
        "colab_type": "code",
        "outputId": "47d9dca3-1704-4d33-dddf-e077eaa9cd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrhCo3NvX3T9",
        "colab_type": "code",
        "outputId": "5652a272-88d7-4a91-ed0c-30b3fb87bb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRHH3YxrYGEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZSHBrJAbDYd",
        "colab_type": "text"
      },
      "source": [
        "Mount your Google drive folder on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgE1tW0gYJmA",
        "colab_type": "code",
        "outputId": "1163c05a-8777-42ac-e5b5-2a7c5cb41e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJw6zsJbpN0",
        "colab_type": "code",
        "outputId": "3c058577-1512-4f16-ace2-3d3502cc6dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Keyphrase Extraction using BERT"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Keyphrase Extraction using BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhSCX9jUcs7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"maui-semeval2010-train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1OWH1fAc0J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt = sorted([f for f in os.listdir(train_path) if not f.endswith(\"-justTitle.txt\") and not f.endswith(\".key\") and not f.endswith(\"-CrowdCountskey\")])\n",
        "key = sorted([f for f in os.listdir(train_path) if f.endswith(\".key\")])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te4Rgrs8c4vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filekey = dict()\n",
        "for i, k in enumerate(txt):\n",
        "    filekey[key[i]] = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzUim3UYc8bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(key):\n",
        "    sentences = \"\"\n",
        "    for line in open(train_path + \"/\" + filekey[key], encoding=\"utf8\"):\n",
        "        sentences += (\" \" + line.rstrip())\n",
        "    tokens = sent_tokenize(sentences)\n",
        "    key_file = open(train_path + \"/\" + str(key),encoding=\"utf8\")\n",
        "    keys = [line.strip() for line in key_file]\n",
        "    key_sent = []\n",
        "    labels = []\n",
        "    for token in tokens:\n",
        "        z = ['O'] * len(token.split())\n",
        "        for k in keys:\n",
        "            if k in token:\n",
        "                \n",
        "                if len(k.split())==1:\n",
        "                    try:\n",
        "                        z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "                elif len(k.split())>1:\n",
        "                    try:\n",
        "                        if token.lower().split().index(k.lower().split()[0]) and token.lower().split().index(k.lower().split()[-1]):\n",
        "                            z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
        "                            for j in range(1, len(k.split())):\n",
        "                                z[token.lower().split().index(k.lower().split()[j])] = 'I'\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "        for m, n in enumerate(z):\n",
        "            if z[m] == 'I' and z[m-1] == 'O':\n",
        "                z[m] = 'O'\n",
        "\n",
        "        if set(z) != {'O'}:\n",
        "            labels.append(z) \n",
        "            key_sent.append(token)\n",
        "    return key_sent, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvuVWTXLdBzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_ = []\n",
        "labels_ = []\n",
        "for key, value in filekey.items():\n",
        "    s, l = convert(key)\n",
        "    sentences_.append(s)\n",
        "    labels_.append(l)\n",
        "sentences = [item for sublist in sentences_ for item in sublist]\n",
        "labels = [item for sublist in labels_ for item in sublist]\n",
        "# print(len(sentences), len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_miLPpMeEsS",
        "colab_type": "code",
        "outputId": "1c546eec-5d40-49c0-f6e7-2cd0c56417e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.13.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.16.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHczNmgydGjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdJ4WYIrd5cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 75\n",
        "bs = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_uhKVy3ePJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx = {'B': 0, 'I': 1, 'O': 2}\n",
        "tags_vals = ['B', 'I', 'O']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryNDns3TeTA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVL8i-vyeal9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrqFTD15ed0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHZvdsAehlr",
        "colab_type": "code",
        "outputId": "c5f2ba0c-d29d-46ca-d5c2-3678614dd41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (766 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1001 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ0g8kG-em4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw2zYThUeqrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32RO0v0Jet7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSOn9JMHexOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_mUNgYQe0Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqV8fFzafI7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN6L7l9Ogn_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X46BgkHSigFl",
        "colab_type": "code",
        "outputId": "ab99b6a6-5dc0-44b5-cad8-32adac122502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On2yCGITiTTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU93KAMdiXn9",
        "colab_type": "code",
        "outputId": "4b2e3cc3-9b52-46f4-ffa8-bc729c5c8506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "epochs = 4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print(\"Loss: {}\".format(eval_loss))\n",
        "    print(\"Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    print(\"F1 Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.18311426283653118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [01:23<04:11, 83.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.13611818739661463\n",
            "Accuracy: 0.976580361225423\n",
            "F1 Score: 0.27885068299576077\n",
            "Train loss: 0.12400971079045091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [02:47<02:47, 83.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.10660302914954999\n",
            "Accuracy: 0.9738134430727027\n",
            "F1 Score: 0.35861038475905865\n",
            "Train loss: 0.09077490636817187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [04:11<01:23, 83.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0990755389685984\n",
            "Accuracy: 0.9691689529035208\n",
            "F1 Score: 0.3988077496274217\n",
            "Train loss: 0.07289469123563984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [05:35<00:00, 83.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.09778740532972195\n",
            "Accuracy: 0.9691100823045266\n",
            "F1 Score: 0.40851315400532073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAZ-NNFNiq7m",
        "colab_type": "code",
        "outputId": "4f427b38-2da0-4dac-a4d3-d38c24b53fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                              attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = model(b_input_ids, token_type_ids=None,\n",
        "                       attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    true_labels.append(label_ids)\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_examples += b_input_ids.size(0)\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
        "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
        "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.09778740532972195\n",
            "Validation Accuracy: 0.9691100823045266\n",
            "Validation F1-Score: 0.40851315400532073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuJcLnqNn2O1",
        "colab_type": "text"
      },
      "source": [
        "**KeyWord Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWQSVEyInZqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.summarization import keywords\n",
        "def keywordextract(string):\n",
        "    \n",
        "    text = string\n",
        "    tkns = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
        "    segments_ids = [0] * len(tkns)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    logit = model(tokens_tensor, token_type_ids=None,\n",
        "                                  attention_mask=segments_tensors)\n",
        "    logit = logit.detach().cpu().numpy()\n",
        "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
        "    for k, j in enumerate(prediction[0]):\n",
        "        if j==1 or j==0:\n",
        "            print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgerB01Fn-fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"h1_7.txt\") as text:\n",
        "  for rec in text:\n",
        "    keywordextract(text)\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7BX9sFCoYg5",
        "colab_type": "code",
        "outputId": "174ec7b7-4ab7-4220-96ea-4bbcc294a65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.summarization import keywords\n",
        "text = \"Mobiles are mobile devices that are used for mobile communication\"\n",
        "keywordextract(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGdIKzjiodA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}